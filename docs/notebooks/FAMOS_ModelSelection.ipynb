{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PEtab Select FAMOS\n",
    "In this notebook we'll run the model selection example from `PEtab Select: specification standard and supporting software for automated model selection` by Pathirana et. al with basico. This assumes you installed basico with optional PEtab support using \n",
    "\n",
    "    pip install copasi-basico[petab]\n",
    "\n",
    "We begin by downloading the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/copasi/basico/raw/a4ebfa0575b3a0c569ea7274bed71657207c883e/tests/famos.zip\n",
    "!unzip -qq -o famos.zip\n",
    "!rm -f famos.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now import basico and petab_select to evaluate the problem. The `evaluate_problem` function will calibrate all models suggested by petab_select returning the best overall found model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from petab_select import Problem\n",
    "from basico.petab import evaluate_problem\n",
    "import basico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the main parameter to tweak is the evaluation function, that one defines what optimization methods should be run on each suggested model. The default evaluation will run a couple of steps of a global optimization method, followed by some steps of a local optimizer. That is of coure rather arbitrary and will not yield the best results in many cases. So lets define an evaluation function here just to see how it is done: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fun():\n",
    "    \"\"\"Evaluation function for currently loaded model\n",
    "\n",
    "    This function does take the currently loaded model `get_current_model()` and\n",
    "    perform parameter estimation on it. \n",
    "\n",
    "    It is supposed to return the solution as returned by `run_parameter_estimation`.\n",
    "\n",
    "    :return: Solution of parameter estimation\n",
    "    :rtype: pandas.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    # run genetic algorithm, important that update_model=True to ensure \n",
    "    # that the following parameter estimation is based on the result of the genetic algorithm\n",
    "    basico.run_parameter_estimation(method=basico.PE.GENETIC_ALGORITHM_SR, update_model=True,\n",
    "                                    settings={'method': {\n",
    "                                        'Number of Generations': 5,\n",
    "                                        'Population Size': 10,\n",
    "                                        'Stop after # Stalled Generations': 30\n",
    "                                        }})\n",
    "    # refine the result with a local optimization method\n",
    "    sol = basico.run_parameter_estimation(method=basico.PE.NL2SOL, update_model=True,\n",
    "                                            settings={'method': {\n",
    "                                                'Iteration Limit': 2000,\n",
    "                                            }}\n",
    "                                          )\n",
    "    return sol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that being done, lets load the petab select problem and evaluate it, depending on the function chosen above, this might take a while. A parallel version is in the works for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = Problem.from_yaml('./famos/petab_select_problem.yaml')\n",
    "best = evaluate_problem(problem, evaluation=eval_fun, temp_dir='./tmp_selection', delete_temp_files=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so lets see what we got, for this we define a print function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper method to view model attributes.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124mModel subspace ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mmodel_subspace_id\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     12\u001b[0m     )\n\u001b[0;32m---> 14\u001b[0m print_model(\u001b[43mbest\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best' is not defined"
     ]
    }
   ],
   "source": [
    "def print_model(model) -> None:\n",
    "    \"\"\"Helper method to view model attributes.\"\"\"\n",
    "    print(\n",
    "        f\"\"\"\\\n",
    "Model subspace ID: {model.model_subspace_id}\n",
    "PEtab YAML location: {model.petab_yaml}\n",
    "Custom model parameters: {model.parameters}\n",
    "Model hash: {model.get_hash()}\n",
    "Model ID: {model.model_id}\n",
    "{problem.criterion}: {model.get_criterion(problem.criterion, compute=False)}\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "print_model(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a_0ac_k05': 1,\n",
       " 'a_0ac_k08': 'estimate',\n",
       " 'a_0ac_k12': 1,\n",
       " 'a_0ac_k16': 1,\n",
       " 'a_k05_k05k08': 1,\n",
       " 'a_k05_k05k12': 'estimate',\n",
       " 'a_k05_k05k16': 1,\n",
       " 'a_k08_k05k08': 1,\n",
       " 'a_k08_k08k12': 1,\n",
       " 'a_k08_k08k16': 1,\n",
       " 'a_k12_k05k12': 'estimate',\n",
       " 'a_k12_k08k12': 1,\n",
       " 'a_k12_k12k16': 1,\n",
       " 'a_k16_k05k16': 1,\n",
       " 'a_k16_k08k16': 1,\n",
       " 'a_k16_k12k16': 'estimate',\n",
       " 'a_k05k08_k05k08k12': 1,\n",
       " 'a_k05k08_k05k08k16': 1,\n",
       " 'a_k05k12_k05k08k12': 'estimate',\n",
       " 'a_k05k12_k05k12k16': 1,\n",
       " 'a_k05k16_k05k08k16': 1,\n",
       " 'a_k05k16_k05k12k16': 1,\n",
       " 'a_k08k12_k05k08k12': 1,\n",
       " 'a_k08k12_k08k12k16': 1,\n",
       " 'a_k08k16_k05k08k16': 1,\n",
       " 'a_k08k16_k08k12k16': 1,\n",
       " 'a_k12k16_k05k12k16': 1,\n",
       " 'a_k12k16_k08k12k16': 'estimate',\n",
       " 'a_k05k08k12_4ac': 1,\n",
       " 'a_k05k08k16_4ac': 1,\n",
       " 'a_k05k12k16_4ac': 1,\n",
       " 'a_k08k12k16_4ac': 'estimate'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a_0ac_k08': 0.4085094414628759,\n",
       " 'a_k05_k05k12': 30.888199302449056,\n",
       " 'a_k12_k05k12': 8.267793085364918,\n",
       " 'a_k16_k12k16': 10.424806975437063,\n",
       " 'a_k05k12_k05k08k12': 4.872782833429837,\n",
       " 'a_k12k16_k08k12k16': 33.03771578079315,\n",
       " 'a_k08k12k16_4ac': 53.80176047873337,\n",
       " 'a_b': 0.06675795470746987}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.estimated_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-basico",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
